{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will **explore in depth and compare** some optimization techniques, as well as their contributes and challenges: \n",
    "\n",
    "-   *Prompt engineering*\n",
    "-   *Retrieval Augmented Generation(RAG)*\n",
    "-   *Fine-tuning*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach alone can be sufficient, especially for simpler or well-defined tasks. Techniques like **few-shot prompting** can notably improve task performance. This method involves providing small task-specific examples to guide the LLM. **Chain of Thought (CoT)** prompting can also improve reasoning capabilities and encourage the model to generate more detailed responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning enables models to perform tasks like extracting JSON-formatted data from text, translating natural language into SQL queries, or adopting a specific writing style.\n",
    "\n",
    "Fine-tuning demands a large, high-quality, task-specific dataset for effective training. You can start with a small dataset and training to see if the method works for your task.\n",
    "\n",
    "It's also not the best choice for incorporating new information into the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation(RAG). Structure explanation and advanced techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of techniques to improve results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG specializes in incorporating external knowledge, enabling the model to access current and varied information. This technique has the following keypoints to consider : \n",
    "\n",
    "-   *Real-Time Updates*: It is more adept at dealing with evolving datasets and can provide more up-to-date responses.\n",
    "-   *Complexity in Integration*: Setting up a RAG system is more complex than basic prompting.\n",
    "-   *Data Managment*: Managing and updating the external data sources is crucial for maintaining the accuracy and relevance of its outputs.\n",
    "-   *Retrieval accuracy*: Ensuring precise embedding retrieval is crucial in RAG systems to guarantee reliable and comprehensive responses to user queries. For that, **we will demonstrate how Activeloopâ€™s Deep Memory method can greatly increase the recall of embedding retrieval**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next steps, we will explore some techniques to improve RAG. The process of querying in LlamaIndex is structured around this key componentes : \n",
    "\n",
    "-   *Retrievers*: Class designed to retrieve a set of nodes from an index based on a query.\n",
    "-   *Query Engine*: Class that process the query and return a response object. Uses the retrieveres to find relevant data and uses the response synthesizer to create the final answer.\n",
    "-   *Query Transform*: Class that improves the original query.\n",
    "\n",
    "This components can improve the performance of the RAG solution. However, there's also some other advanced techniques that can be implemented too:\n",
    "\n",
    "-   *Query Construction*: The techniques is focused on convert the user query to a format more appropiated with different data sources. Can be implemented different approaches:\n",
    "    -   *MetadataFilter* classes: An autoretriever that translates natural language into unstructured queries.\n",
    "    -   *Text-to-SQL*: For relational databases. Converts natural language to SQL requests.However, can appear problems like hallucination. To avoid this issue, an accurate description of the database and some few shots of example should be providen the LLM. \n",
    "-   *Query Expansion*: Add phrases or another data to the user query to improve the search of data. It's useful when the original query is too short or not very specific. One approach to do it is utilizing the `synonym_expand_policy` from the `KnowledgeGraphRAGRetriever` class. This technique combined with *Query Transformation* is so useful.\n",
    "-   *Query Tranformation*: Modifies the original query to make it more effective. This transformations include changes in the query's structure, the use of synonyms or the inclusion of contextual information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To practice with an example, we will implement a query engine:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we download a text file that serves as source document. Is a compilation of all the essays Paul Graham wrote on his blog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of SubQuestionoQueryEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paul_graham\\\\paul_graham_essay (1).txt'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wget\n",
    "import os\n",
    "\n",
    "os.makedirs('paul_graham', exist_ok=True)\n",
    "file_path = os.path.join('paul_graham', 'paul_graham_essay.txt')\n",
    "wget.download('https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt', out=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "Settings.embed_model = OllamaEmbeddings(model=\"llama3.1:8b\") # Load it into the setting of llama index\n",
    "Settings.llm = OllamaLLM(model=\"llama3.1:8b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `SimpleDirectoryReader` class to read al the documents of a given directory automatically.\n",
    "\n",
    "After that, we add some changes to the settings to fix the size of the chunks and the overlap between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"./paul_graham\").load_data()\n",
    "\n",
    "\n",
    "Settings.chunk_size = 512\n",
    "Settings.chunk_overlap = 64\n",
    "node_parser = Settings.node_parser\n",
    "nodes = node_parser.get_nodes_from_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we got the nodes with the `node_parser` object, we store them into a vector store database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\deeplake\\util\\check_latest_version.py:32: UserWarning: A newer version of deeplake (3.9.26) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://alejandrotormun/LlamaIndex_paulgraham_essays already exists, loading from the storage\n",
      "Uploading data to deeplake dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/88 [00:27<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m storage_context\u001b[38;5;241m.\u001b[39mdocstore\u001b[38;5;241m.\u001b[39madd_documents(nodes)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Create the VectorStore index\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m vector_index \u001b[38;5;241m=\u001b[39m \u001b[43mVectorStoreIndex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py:76\u001b[0m, in \u001b[0;36mVectorStoreIndex.__init__\u001b[1;34m(self, nodes, use_async, store_nodes_override, embed_model, insert_batch_size, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_model \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     70\u001b[0m     resolve_embed_model(embed_model, callback_manager\u001b[38;5;241m=\u001b[39mcallback_manager)\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m embed_model\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m Settings\u001b[38;5;241m.\u001b[39membed_model\n\u001b[0;32m     73\u001b[0m )\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insert_batch_size \u001b[38;5;241m=\u001b[39m insert_batch_size\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\llama_index\\core\\indices\\base.py:77\u001b[0m, in \u001b[0;36mBaseIndex.__init__\u001b[1;34m(self, nodes, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index_struct \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m nodes \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m---> 77\u001b[0m     index_struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_index_from_nodes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_struct \u001b[38;5;241m=\u001b[39m index_struct\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage_context\u001b[38;5;241m.\u001b[39mindex_store\u001b[38;5;241m.\u001b[39madd_index_struct(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_struct)\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py:310\u001b[0m, in \u001b[0;36mVectorStoreIndex.build_index_from_nodes\u001b[1;34m(self, nodes, **insert_kwargs)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(content_nodes) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(nodes):\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome nodes are missing content, skipping them...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_index_from_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minsert_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py:279\u001b[0m, in \u001b[0;36mVectorStoreIndex._build_index_from_nodes\u001b[1;34m(self, nodes, **insert_kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m     run_async_tasks(tasks)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 279\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_nodes_to_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minsert_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m index_struct\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py:233\u001b[0m, in \u001b[0;36mVectorStoreIndex._add_nodes_to_index\u001b[1;34m(self, index_struct, nodes, show_progress, **insert_kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nodes_batch \u001b[38;5;129;01min\u001b[39;00m iter_batch(nodes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insert_batch_size):\n\u001b[0;32m    232\u001b[0m     nodes_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_node_with_embedding(nodes_batch, show_progress)\n\u001b[1;32m--> 233\u001b[0m     new_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_vector_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minsert_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vector_store\u001b[38;5;241m.\u001b[39mstores_text \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_nodes_override:\n\u001b[0;32m    236\u001b[0m         \u001b[38;5;66;03m# NOTE: if the vector store doesn't store text,\u001b[39;00m\n\u001b[0;32m    237\u001b[0m         \u001b[38;5;66;03m# we need to add the nodes to the index struct and document store\u001b[39;00m\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m node, new_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(nodes_batch, new_ids):\n\u001b[0;32m    239\u001b[0m             \u001b[38;5;66;03m# NOTE: remove embedding from node to avoid duplication\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\llama_index\\vector_stores\\deeplake\\base.py:244\u001b[0m, in \u001b[0;36mDeepLakeVectorStore.add\u001b[1;34m(self, nodes, **add_kwargs)\u001b[0m\n\u001b[0;32m    235\u001b[0m     text\u001b[38;5;241m.\u001b[39mappend(node\u001b[38;5;241m.\u001b[39mget_content(metadata_mode\u001b[38;5;241m=\u001b[39mMetadataMode\u001b[38;5;241m.\u001b[39mNONE))\n\u001b[0;32m    237\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m: embedding,\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id_tensor_name: id_,\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: text,\n\u001b[0;32m    242\u001b[0m }\n\u001b[1;32m--> 244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_vectorstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\deeplake\\core\\vectorstore\\deeplake_vectorstore.py:229\u001b[0m, in \u001b[0;36mVectorStore.add\u001b[1;34m(self, embedding_function, embedding_data, embedding_tensor, return_ids, rate_limiter, **tensors)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd\u001b[39m(\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    152\u001b[0m     embedding_function: Optional[Union[Callable, List[Callable]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtensors,\n\u001b[0;32m    162\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[List[\u001b[38;5;28mstr\u001b[39m]]:\n\u001b[0;32m    163\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Adding elements to deeplake vector store.\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \n\u001b[0;32m    165\u001b[0m \u001b[38;5;124;03m    Tensor names are specified as parameters, and data for each tensor is specified as parameter values. All data must of equal length.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;124;03m        Optional[List[str]]: List of ids if ``return_ids`` is set to True. Otherwise, None.\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrate_limiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrate_limiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\deeplake\\core\\vectorstore\\dataset_handlers\\client_side_dataset_handler.py:139\u001b[0m, in \u001b[0;36mClientSideDH.add\u001b[1;34m(self, embedding_function, embedding_data, embedding_tensor, return_ids, rate_limiter, **tensors)\u001b[0m\n\u001b[0;32m    133\u001b[0m processed_tensors, id_ \u001b[38;5;241m=\u001b[39m dataset_utils\u001b[38;5;241m.\u001b[39mpreprocess_tensors(\n\u001b[0;32m    134\u001b[0m     embedding_data, embedding_tensor, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtensors\n\u001b[0;32m    135\u001b[0m )\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m id_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 139\u001b[0m \u001b[43mdataset_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend_or_ingest_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocessed_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessed_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrate_limiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrate_limiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\deeplake\\core\\vectorstore\\vector_search\\dataset\\dataset.py:535\u001b[0m, in \u001b[0;36mextend_or_ingest_dataset\u001b[1;34m(processed_tensors, dataset, embedding_function, embedding_tensor, embedding_data, rate_limiter, logger)\u001b[0m\n\u001b[0;32m    533\u001b[0m rate_limiter \u001b[38;5;241m=\u001b[39m populate_rate_limiter(rate_limiter)\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# TODO: Add back the old logic with checkpointing after indexing is fixed\u001b[39;00m\n\u001b[1;32m--> 535\u001b[0m \u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocessed_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrate_limiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\deeplake\\core\\vectorstore\\vector_search\\dataset\\dataset.py:499\u001b[0m, in \u001b[0;36mextend\u001b[1;34m(embedding_function, embedding_data, embedding_tensor, processed_tensors, dataset, rate_limiter, _extend_batch_size, logger)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUploading data to deeplake dataset.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 499\u001b[0m     \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\deeplake\\core\\dataset\\dataset.py:3293\u001b[0m, in \u001b[0;36mDataset.extend\u001b[1;34m(self, samples, skip_ok, append_empty, ignore_errors, progressbar)\u001b[0m\n\u001b[0;32m   3291\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices:\n\u001b[0;32m   3292\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3293\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_append_or_extend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3294\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3295\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   3296\u001b[0m \u001b[43m            \u001b[49m\u001b[43mskip_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_ok\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3297\u001b[0m \u001b[43m            \u001b[49m\u001b[43mappend_empty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mappend_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3298\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3299\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   3300\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m ignore_errors:\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\deeplake\\core\\dataset\\dataset.py:3187\u001b[0m, in \u001b[0;36mDataset._append_or_extend\u001b[1;34m(self, sample, extend, skip_ok, append_empty)\u001b[0m\n\u001b[0;32m   3185\u001b[0m             tensor\u001b[38;5;241m.\u001b[39m_extend([\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m extend_extra_nones)\n\u001b[0;32m   3186\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3187\u001b[0m         \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_append\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3188\u001b[0m     tensors_appended\u001b[38;5;241m.\u001b[39mappend(k)\n\u001b[0;32m   3189\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\deeplake\\core\\tensor.py:432\u001b[0m, in \u001b[0;36mTensor._append\u001b[1;34m(self, sample)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_append\u001b[39m(\u001b[38;5;28mself\u001b[39m, sample: InputSample):\n\u001b[1;32m--> 432\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\deeplake\\core\\tensor.py:316\u001b[0m, in \u001b[0;36mTensor._extend\u001b[1;34m(self, samples, progressbar, ignore_errors)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_initialization()\n\u001b[0;32m    315\u001b[0m [f() \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m_update_hooks\u001b[38;5;241m.\u001b[39mvalues())]\n\u001b[1;32m--> 316\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlink_callback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extend_links\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m dataset_written(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvalidate_libdeeplake_dataset()\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\deeplake\\core\\chunk_engine.py:1234\u001b[0m, in \u001b[0;36mChunkEngine.extend\u001b[1;34m(self, samples, progressbar, link_callback, pg_callback, ignore_errors, verified_samples)\u001b[0m\n\u001b[0;32m   1226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_sequence(\n\u001b[0;32m   1227\u001b[0m         samples,\n\u001b[0;32m   1228\u001b[0m         progressbar,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1231\u001b[0m         verified_samples,\n\u001b[0;32m   1232\u001b[0m     )\n\u001b[0;32m   1233\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1234\u001b[0m     verified_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1235\u001b[0m \u001b[43m        \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpg_callback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpg_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverified_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverified_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1240\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m link_callback:\n\u001b[0;32m   1242\u001b[0m         verified_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_samples_for_link_callback(\n\u001b[0;32m   1243\u001b[0m             verified_samples\n\u001b[0;32m   1244\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\deeplake\\core\\chunk_engine.py:1097\u001b[0m, in \u001b[0;36mChunkEngine._extend\u001b[1;34m(self, samples, progressbar, pg_callback, update_commit_diff, ignore_errors, verified_samples)\u001b[0m\n\u001b[0;32m   1091\u001b[0m verified_samples \u001b[38;5;241m=\u001b[39m verified_samples \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_each_sample(\n\u001b[0;32m   1092\u001b[0m     samples, ignore_errors\u001b[38;5;241m=\u001b[39mignore_errors\n\u001b[0;32m   1093\u001b[0m )\n\u001b[0;32m   1094\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sanitize_samples(samples, ignore_errors\u001b[38;5;241m=\u001b[39mignore_errors)\n\u001b[0;32m   1095\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_samples_to_chunks(\n\u001b[0;32m   1096\u001b[0m     samples,\n\u001b[1;32m-> 1097\u001b[0m     start_chunk\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_appended_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mallow_copy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1098\u001b[0m     register\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1099\u001b[0m     progressbar\u001b[38;5;241m=\u001b[39mprogressbar,\n\u001b[0;32m   1100\u001b[0m     update_commit_diff\u001b[38;5;241m=\u001b[39mupdate_commit_diff,\n\u001b[0;32m   1101\u001b[0m     pg_callback\u001b[38;5;241m=\u001b[39mpg_callback,\n\u001b[0;32m   1102\u001b[0m     return_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1103\u001b[0m     ignore_errors\u001b[38;5;241m=\u001b[39mignore_errors,\n\u001b[0;32m   1104\u001b[0m )\n\u001b[0;32m   1105\u001b[0m verified_samples \u001b[38;5;241m=\u001b[39m verified_samples \u001b[38;5;129;01mor\u001b[39;00m samples\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m verified_samples\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\deeplake\\core\\chunk_engine.py:564\u001b[0m, in \u001b[0;36mChunkEngine.last_appended_chunk\u001b[1;34m(self, allow_copy)\u001b[0m\n\u001b[0;32m    562\u001b[0m chunk_commit_id, tkey \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_chunk_commit(chunk_name)\n\u001b[0;32m    563\u001b[0m chunk_key \u001b[38;5;241m=\u001b[39m get_chunk_key(tkey, chunk_name, chunk_commit_id)\n\u001b[1;32m--> 564\u001b[0m chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    565\u001b[0m chunk\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;241m=\u001b[39m chunk_key\n\u001b[0;32m    566\u001b[0m chunk\u001b[38;5;241m.\u001b[39mid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_appended_chunk_id\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\deeplake\\core\\chunk_engine.py:580\u001b[0m, in \u001b[0;36mChunkEngine.get_chunk\u001b[1;34m(self, chunk_key, partial_chunk_bytes)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, chunk_key: \u001b[38;5;28mstr\u001b[39m, partial_chunk_bytes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseChunk:\n\u001b[1;32m--> 580\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_deeplake_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartial_bytes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartial_chunk_bytes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    585\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partial_chunk_bytes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunk\u001b[38;5;241m.\u001b[39mdata_bytes, PartialReader):\n\u001b[0;32m    587\u001b[0m         chunk\u001b[38;5;241m.\u001b[39m_make_data_bytearray()\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\deeplake\\core\\storage\\lru_cache.py:166\u001b[0m, in \u001b[0;36mLRUCache.get_deeplake_object\u001b[1;34m(self, path, expected_class, meta, url, partial_bytes)\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    163\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected class should be subclass of BaseChunk when url is True.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    164\u001b[0m         )\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 166\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, DeepLakeMemoryObject):\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(item) \u001b[38;5;241m!=\u001b[39m expected_class:\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\deeplake\\core\\storage\\lru_cache.py:217\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_storage \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m         \u001b[38;5;66;03m# fetch from storage, may throw KeyError\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_storage\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _get_nbytes(result) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_size:  \u001b[38;5;66;03m# insert in cache if it fits\u001b[39;00m\n\u001b[0;32m    220\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insert_in_cache(path, result)\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\deeplake\\core\\storage\\s3.py:236\u001b[0m, in \u001b[0;36mS3Provider.__getitem__\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, path):\n\u001b[0;32m    224\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Gets the object present at the path.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \n\u001b[0;32m    226\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;124;03m        S3GetError: Any other error other than KeyError while retrieving the object.\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\deeplake\\core\\storage\\s3.py:278\u001b[0m, in \u001b[0;36mS3Provider.get_bytes\u001b[1;34m(self, path, start_byte, end_byte)\u001b[0m\n\u001b[0;32m    276\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath, path))\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_byte\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_byte\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m botocore\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mClientError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNoSuchKey\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\deeplake\\core\\storage\\s3.py:251\u001b[0m, in \u001b[0;36mS3Provider._get_bytes\u001b[1;34m(self, path, start_byte, end_byte)\u001b[0m\n\u001b[0;32m    249\u001b[0m     range_kwarg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRange\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbytes=0-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_byte\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    250\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mget_object(Bucket\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbucket, Key\u001b[38;5;241m=\u001b[39mpath, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrange_kwarg)\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBody\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\botocore\\response.py:99\u001b[0m, in \u001b[0;36mStreamingBody.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Read at most amt bytes from the stream.\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03mIf the amt argument is omitted, read all data.\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 99\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m URLLib3ReadTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;66;03m# TODO: the url will be None as urllib3 isn't setting it yet\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(endpoint_url\u001b[38;5;241m=\u001b[39me\u001b[38;5;241m.\u001b[39murl, error\u001b[38;5;241m=\u001b[39me)\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\urllib3\\response.py:949\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    946\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[0;32m    947\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[1;32m--> 949\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    951\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\urllib3\\response.py:873\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[1;34m(self, amt, read1)\u001b[0m\n\u001b[0;32m    870\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[1;32m--> 873\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    874\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[0;32m    875\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[0;32m    876\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[0;32m    883\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\urllib3\\response.py:856\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[1;34m(self, amt, read1)\u001b[0m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:481\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 481\u001b[0m         s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_safe_read\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m IncompleteRead:\n\u001b[0;32m    483\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:630\u001b[0m, in \u001b[0;36mHTTPResponse._safe_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_safe_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, amt):\n\u001b[0;32m    624\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read the number of bytes requested.\u001b[39;00m\n\u001b[0;32m    625\u001b[0m \n\u001b[0;32m    626\u001b[0m \u001b[38;5;124;03m    This function should be used when <amt> bytes \"should\" be present for\u001b[39;00m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;124;03m    reading. If the bytes are truly not available (due to EOF), then the\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;124;03m    IncompleteRead exception can be used to detect the problem.\u001b[39;00m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m<\u001b[39m amt:\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(data, amt\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(data))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1275\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1276\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1277\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from llama_index.vector_stores.deeplake import DeepLakeVectorStore\n",
    "import json\n",
    "from llama_index.core.storage.storage_context import StorageContext\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "# CHANGE THIS CODE TO LOAD YOUR CREDENTIALS\n",
    "with open(\"../data/keys.json\", \"rb\") as file:\n",
    "    data = json.load(file)\n",
    "    activeloop_org_id = data['NameOrg']\n",
    "    activeloop_dataset_name = \"LlamaIndex_paulgraham_essays\"\n",
    "    dataset_path = f\"hub://{activeloop_org_id}/{activeloop_dataset_name}\"\n",
    "    os.environ['ACTIVELOOP_TOKEN'] = data['ActiveLoopKey']\n",
    "\n",
    "\n",
    "# Create a vector store into ActiveLoop cloud\n",
    "vector_store = DeepLakeVectorStore(dataset_path=dataset_path, overwrite=False)\n",
    "# Create the StorageContext object\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "# Add the nodes obtained\n",
    "storage_context.docstore.add_documents(nodes)\n",
    "# Create the VectorStore index\n",
    "vector_index = VectorStoreIndex(nodes, storage_context=storage_context)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have created the index, it can serves as the basis for defining the query engine. We initiate the query engine by using the vector index object with the method `.as_query_engine()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"entity\": \"founder_of_The_YCombinatorstartup_accelerator\", \"reason\": \"Paul Graham is mentioned as 'I' in the essay, stating that he kept working on YC (YC = The Y Combinator) till March 2014.\"}\n"
     ]
    }
   ],
   "source": [
    "query_engine = vector_index.as_query_engine(similarity_top_k=15)\n",
    "response = query_engine.query(\"What does Paul Graham do?\")\n",
    "print(response.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can improve the previous code, giving some metadata, and using the **Sub Question Query Engine**, a querying method that can generate several sub-questions from the user's main question : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()  # Apply the patch for nested event loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something important to consider is that this technique works with JSON format. Since we are using Ollama models, we have to specify to use this format on model's answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = OllamaLLM(model=\"llama3.1:8b\", format=\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 3 sub questions.\n",
      "\u001b[1;3;38;2;237;90;200m[pg_essay] Q: What did Paul Graham work on before joining YC?\n",
      "\u001b[0m\u001b[1;3;38;2;90;149;237m[pg_essay] Q: How was Paul Grahams life during his time at YC?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203m[pg_essay] Q: What did Paul Graham do after leaving YC?\n",
      "\u001b[0m\u001b[1;3;38;2;90;149;237m[pg_essay] A: { \n",
      "\"Paul Graham's life during his time at Y Combinator reflected his independent-mindedness and ability to adapt to rapid change. He was less influenced by conventional VC practices and customs, which were still based on old constraints despite significant changes in the world. This led him to take unconventional steps, such as renaming the organization after a mathematical concept (the Y combinator), adopting an untraditional color scheme (orange), and transitioning back to self-funding even when it became successful. Graham's perspective also acknowledged that customary VC practices were outdated and that Y Combinator aimed to challenge this status quo by fostering new startups that would not have existed otherwise. Moreover, his approach to venture capital was shaped by the idea of creating a 'Y combinator' in other fields, such as essay writing, where he predicted that rapid change could make traditional customs obsolete.\" \n",
      " : []}\n",
      "\n",
      " \n",
      " \n",
      " \n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      " \n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203m[pg_essay] A: { \"started painting\" : \"I wanted to see how good I could get if I really focused on it. So the day after I stopped working on YC, I started painting.\", \"went back to being self-funded with Y Combinator, but continued pursuing other interests such as painting and writing essays.\"  : \"Essay writing was also an outlet for me, as seen in [11], where I reflected on customs and how they relate to rapid change. This also shows my interest in writing beyond just publishing it online.\"}\n",
      "\n",
      " \n",
      " \n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200m[pg_essay] A: {\"Before joining YC he worked on writing essays and revisited working on Lisp.\" \n",
      "\n",
      "   : \"I had not originally intended YC to be a full-time job. I was going to do three things: hack, write\" \n",
      "\n",
      "   , \"Then in March 2015 I started working on Lisp again.\" \n",
      "\n",
      "   : \"writing essays, and working on other projects like Lisp\"}\n",
      "\n",
      " \n",
      " \t      \n",
      "      \n",
      "\u001b[0m>>> The final response:\n",
      " { \"Before YC his life was marked by independent-mindedness, where he worked on writing essays and revisited working on Lisp in his free time. He had a flexible schedule, which allowed him to pursue multiple interests simultaneously. His work-life balance was maintained through these various projects.\" \n",
      " : \"During YC, Paul Graham continued to embody his independent nature despite being part of the startup accelerator. He introduced unconventional elements such as renaming the organization and adopting an orange color scheme, reflecting his resistance to conventional VC practices and customs. This period also saw him transition back to self-funding even when Y Combinator became successful.\" \n",
      " , \"After leaving YC, Paul Graham's life took a different turn, marked by his pursuit of new interests outside of Y Combinator. He started painting full-time, which was a deliberate choice to see how good he could get at it, showcasing his continued interest in trying new things and exploring his creativity.\" \n",
      " : \"Furthermore, after leaving YC, Paul Graham also continued to be self-funded with Y Combinator, but made time for other hobbies such as essay writing and painting. This demonstrated a preference for maintaining control over his work schedule while still engaging in personal pursuits that brought him joy.\" }\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.query_engine import SubQuestionQueryEngine\n",
    "\n",
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=query_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"pg_essay\",\n",
    "            description=\"Paul Graham essay on What I Worked On\"\n",
    "        )\n",
    "    )\n",
    "]\n",
    "\n",
    "query_engine = SubQuestionQueryEngine.from_defaults(\n",
    "    query_engine_tools=query_engine_tools,\n",
    "    use_async=True\n",
    ")\n",
    "\n",
    "response = query_engine.query(\n",
    "    \"How was Paul Grahams life different before, during, and after 'YC'?\"\n",
    ")\n",
    "print( \">>> The final response:\\n\", response )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen, we get a JSON format response. We can remove that format with the following code : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ \"Before YC his life was marked by independent-mindedness, where he worked on writing essays and revisited working on Lisp in his free time. He had a flexible schedule, which allowed him to pursue multiple interests simultaneously. His work-life balance was maintained through these various projects.\" \n",
      " : \"During YC, Paul Graham continued to embody his independent nature despite being part of the startup accelerator. He introduced unconventional elements such as renaming the organization and adopting an orange color scheme, reflecting his resistance to conventional VC practices and customs. This period also saw him transition back to self-funding even when Y Combinator became successful.\" \n",
      " , \"After leaving YC, Paul Graham's life took a different turn, marked by his pursuit of new interests outside of Y Combinator. He started painting full-time, which was a deliberate choice to see how good he could get at it, showcasing his continued interest in trying new things and exploring his creativity.\" \n",
      " : \"Furthermore, after leaving YC, Paul Graham also continued to be self-funded with Y Combinator, but made time for other hobbies such as essay writing and painting. This demonstrated a preference for maintaining control over his work schedule while still engaging in personal pursuits that brought him joy.\" }\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before YC his life was marked by independent-mindedness, where he worked on writing essays and revisited working on Lisp in his free time. He had a flexible schedule, which allowed him to pursue multiple interests simultaneously. His work-life balance was maintained through these various projects.: During YC, Paul Graham continued to embody his independent nature despite being part of the startup accelerator. He introduced unconventional elements such as renaming the organization and adopting an orange color scheme, reflecting his resistance to conventional VC practices and customs. This period also saw him transition back to self-funding even when Y Combinator became successful.\n",
      "After leaving YC, Paul Graham's life took a different turn, marked by his pursuit of new interests outside of Y Combinator. He started painting full-time, which was a deliberate choice to see how good he could get at it, showcasing his continued interest in trying new things and exploring his creativity.: Furthermore, after leaving YC, Paul Graham also continued to be self-funded with Y Combinator, but made time for other hobbies such as essay writing and painting. This demonstrated a preference for maintaining control over his work schedule while still engaging in personal pursuits that brought him joy.\n"
     ]
    }
   ],
   "source": [
    "response_dict = json.loads(str(response))\n",
    "plain_text_lines = []\n",
    "\n",
    "for key, value in response_dict.items():\n",
    "    plain_text_lines.append(f\"{key}: {value}\")\n",
    "\n",
    "plain_text_response = \"\\n\".join(plain_text_lines)\n",
    "\n",
    "print(plain_text_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Retrievers and Reranking with FlaskRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can keep improving the quality of the response by creating a **custom retriever**. Custom retrievers are a combination of different retriever styles. The `RetrieverQueryEngine` class operates with a designed retriever. There are two main `RetrieverQueryEngine` types:\n",
    "\n",
    "-   *VectorIndexRetriever*: Fetches the top-k nodes that are most similar to the query. It's ideal for situations where precision and relevance to the specific query are paramount, like in detailed research or topic-specific inquiries.\n",
    "-   *SummaryIndexRetriever*: Retrieves all nodes related to the query without prioritazing their relevance. This approach is less concerned with aligning closely to the specific context of the question and more about providing a broad overview. It's useful in scenarios where a comprehensive sweep of information is needed, regardless of the direct relevance to the specific terms of the query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While any retrieval mechanism is capable of extracting multiple chunks from a large document, there's always some irrelevant candidates between the nodes selected. Reranking is re-evaluating and re-ordering search results to present the most relevant options. The **Cohere Reranker** improves the performance of retrieving close content. It sorts the search results according to their relevance to the query. **However, that solution is not open-source, while FlashRank is an oper-source rerank solution.**\n",
    "\n",
    "The process begins with grouping documents into batches, after which the LLM evaluates each batch, giving a **relevance score to each document**. The final step in the reranking process involves aggregating the most relevant documents from all these batches to form the final retrieval response.\n",
    "\n",
    "In the following code we show how to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever at 0x250cc8dd8d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ContextualCompressionRetriever\nbase_retriever\n  Input should be an instance of Runnable [type=is_instance_of, input_value=<llama_index.core.indices...t at 0x0000025107E1E7D0>, input_type=VectorIndexRetriever]\n    For further information visit https://errors.pydantic.dev/2.9/v/is_instance_of",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Create the compression retriever\u001b[39;00m\n\u001b[0;32m     25\u001b[0m compressor \u001b[38;5;241m=\u001b[39m FlashrankRerank()\n\u001b[1;32m---> 26\u001b[0m compression_retriever \u001b[38;5;241m=\u001b[39m \u001b[43mContextualCompressionRetriever\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_compressor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompressor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_retriever\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mretriever\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m compressed_docs \u001b[38;5;241m=\u001b[39m compression_retriever\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat did the president say about Ketanji Jackson Brown\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     32\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\langchain_core\\load\\serializable.py:111\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    110\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\pydantic\\main.py:212\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(self, **data)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[0;32m    211\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[0;32m    214\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    215\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    218\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    219\u001b[0m     )\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for ContextualCompressionRetriever\nbase_retriever\n  Input should be an instance of Runnable [type=is_instance_of, input_value=<llama_index.core.indices...t at 0x0000025107E1E7D0>, input_type=VectorIndexRetriever]\n    For further information visit https://errors.pydantic.dev/2.9/v/is_instance_of"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers.document_compressors import FlashrankRerank\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from llama_index.core import VectorStoreIndex, Document\n",
    "\n",
    "\n",
    "query = \"What is the capital of the United States?\"\n",
    "documents = [\n",
    "   \"Carson City is the capital city of the American state of Nevada. At the  2010 United States Census, Carson City had a population of 55,274.\",\n",
    "   \"The Commonwealth of the Northern Mariana Islands is a group of islands in the Pacific Ocean that are a political division controlled by the United States. Its capital is Saipan.\",\n",
    "   \"Charlotte Amalie is the capital and largest city of the United States Virgin Islands. It has about 20,000 people. The city is on the island of Saint Thomas.\",\n",
    "   \"Washington, D.C. (also known as simply Washington or D.C., and officially as the District of Columbia) is the capital of the United States. It is a federal district. \",\n",
    "   \"Capital punishment (the death penalty) has existed in the United States since before the United States was a country. As of 2017, capital punishment is legal in 30 of the 50 states.\",\n",
    "   \"North Dakota is a state in the United States. 672,591 people lived in North Dakota in the year 2010. The capital and seat of government is Bismarck.\"\n",
    "   ]\n",
    "\n",
    "# Convert raw strings into Document objects\n",
    "doc_objects = [Document(text=doc) for doc in documents]\n",
    "\n",
    "# Create an index from the document objects\n",
    "index = VectorStoreIndex.from_documents(documents=doc_objects)\n",
    "# Create retriever from the index\n",
    "retriever = index.as_retriever()\n",
    "\n",
    "# Create the compression retriever\n",
    "compressor = FlashrankRerank()\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever = retriever\n",
    ")\n",
    "compressed_docs = compression_retriever.invoke(\n",
    "    \"What did the president say about Ketanji Jackson Brown\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Reranking, new rank list for nodes: [2, 0, 5, 4, 3, 1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response with reranking : According to the context information:\n",
      "\n",
      "\"The capital of the United States. It is a federal district.\"\n",
      "\n",
      "So, the answer is: Washington, D.C.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Reranking, new rank list for nodes: [2, 0, 4, 5, 3, 1]\n",
      "Response without reranking : According to the context information, the capital of the United States is Washington, D.C. (also known as simply Washington or D.C., and officially as the District of Columbia).\n"
     ]
    }
   ],
   "source": [
    "from llama_index.postprocessor.rankgpt_rerank import RankGPTRerank\n",
    "from langchain.retrievers.document_compressors import FlashrankRerank\n",
    "from llama_index.core import VectorStoreIndex, Document\n",
    "from llama_index.core import QueryBundle\n",
    "\n",
    "query = \"What is the capital of the United States?\"\n",
    "documents = [\n",
    "   \"Carson City is the capital city of the American state of Nevada. At the  2010 United States Census, Carson City had a population of 55,274.\",\n",
    "   \"The Commonwealth of the Northern Mariana Islands is a group of islands in the Pacific Ocean that are a political division controlled by the United States. Its capital is Saipan.\",\n",
    "   \"Charlotte Amalie is the capital and largest city of the United States Virgin Islands. It has about 20,000 people. The city is on the island of Saint Thomas.\",\n",
    "   \"Washington, D.C. (also known as simply Washington or D.C., and officially as the District of Columbia) is the capital of the United States. It is a federal district. \",\n",
    "   \"Capital punishment (the death penalty) has existed in the United States since before the United States was a country. As of 2017, capital punishment is legal in 30 of the 50 states.\",\n",
    "   \"North Dakota is a state in the United States. 672,591 people lived in North Dakota in the year 2010. The capital and seat of government is Bismarck.\"\n",
    "   ]\n",
    "\n",
    "# Convert raw strings into Document objects\n",
    "doc_objects = [Document(text=doc) for doc in documents]\n",
    "\n",
    "# Create an index from the document objects\n",
    "index = VectorStoreIndex.from_documents(documents=doc_objects)\n",
    "# Create retriever from the index\n",
    "retriever = index.as_retriever()\n",
    "\n",
    "# We create the ReRank object\n",
    "reranker = RankGPTRerank(\n",
    "    llm=Settings.llm,\n",
    "    top_n=3,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "query_engine_reranking = index.as_query_engine(similarity_top_k=10,\n",
    "                      node_postprocessors=[reranker])\n",
    "\n",
    "response = query_engine.query(\n",
    "    \"What is the capital of the United States?\",\n",
    ")\n",
    "print(\"\")\n",
    "print(f\"Response with reranking : {response}\")\n",
    "\n",
    "query_engine_no_reranking = index.as_query_engine(similarity_top_k=10)\n",
    "response = query_engine.query(\n",
    "    \"What is the capital of the United States?\",\n",
    ")\n",
    "print(\"\")\n",
    "print(f\"Response without reranking : {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Retrievals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another alternative for retrieving relevant documents involves using document summaries instead of extracting fragmented snippets or brief text chunks. This technique offers a more thorough grasp of the subject. We will introduce two techniques : \n",
    "\n",
    "-   *Recursive Retrieval*: This technique is **useful for documents with a hierarchical structure**, allowing them to form connections and relations between nodes. **This is evident for PDF's documents**. Here's an example of it's implementation : [link](https://docs.llamaindex.ai/en/stable/examples/query_engine/pdf_tables/recursive_retriever/).\n",
    "-   *Small-to-Big retrieval*: This techniques is divided in two steps : \n",
    "    -   *Initial small search*: Search of concise and short sentences. The objective of this step is to identify with precision the most relevant section, instead of analyzing the whole text since the beginning.\n",
    "    -   *Ampliaton of context-big search*: Once the most relevant section is found, the context is expanded to get a better context(previous ans posterior text).\n",
    "\n",
    "    This technique is useful when the initial query is very short,or when the relation between documents is very complex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deep Memory** is a method developed by ActiveLoop to boost the accuracy of embedding retrieval for RAG systems in DeepLake vector store database. **Deep Memory trains a model that transforms embeddings into a space optimizied for your use case. This reconfiguration significantly improves vector search accuracy.**\n",
    "\n",
    "Deep Memory is effective where query reformulation, query transformation, or documetn re-ranking might cause latency and increased token usage. It boosts retrieval capabilities without negatively impacting the system's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Deep Memory, we have the following steps : \n",
    "\n",
    "1.   *Embeddings*: Vector representation of a set of words. We create them using embedding models as we have seen previously.\n",
    "2.   *Deep Memory Training*: A dataset of query and context pairs trains the Deep Memory model. This training process runs in Deep Lake Cloud, which provides the computational resources and infrastructure for handling the training.\n",
    "3.   *Deep Memory Inference*: The model enters the inference phase, which transforms query embeddings.\n",
    "4.   *Transformed Embeddings*: The result of the inference process is a set of transformed embeddings optimized for a specific use case.\n",
    "5.   *Vector Search*: These optimized embeddings are used in vector search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To put hands-on-practice, we will implement Deep Memory within our workflow. We shoul know that Deep Memory is a **premium feature in ActiveLoop paid plans**. We can use a free trial **(if you follow the ActiveLoop RAG course, you will get an extended free trial)** using GENAI360 promo code in you Deep Lake account.\n",
    "\n",
    "**Note**: For personal projects on a local machine without any cost, is recommended to use **FAISS** as vector store database. It has been implemented for LlamaIndex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mix of techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also combine some of the previous techniques, like **RAG+Fine-tuning**. With fine-tuning we can customize the model for a specific style, which can be useful for domains like medical, financial or any area that requires a highly specialized tone of writing. When combined with RAG, the model becomes adept in a specialized area, and gain access to a vast range of external information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenges of RAG systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main challenges of RAG system are these:\n",
    "\n",
    "-   *Document updates*: When documents are modified, added or eliminated, the corresponding vector needs to be updated.\n",
    "-   *Chunking and data distribution*: The granularity level is vital in achieving accuratte retrieval results. If the chunk size is too large, important details may be missed, and if it's too small, the system might get bogged down in details and miss bigger picture.\n",
    "-   *Diverse Representations in Latent Space*: The presence of different representations(text versus tables or images) in the same latent space can be challenging. These diverse representations can cause conflicts.\n",
    "-   *Compliance*: Non-compliance can lead to legal issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization techniques for RAG systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will presented several optimization strategies : \n",
    "-   *Model selection and hybrid retrieval*: Selecting appropriate models for the embedding and generation phases is critical. Choosing efficient and cheap embedding models can minimize costs while maintaining performance levels, but not in the generation process where an LLM is needed. \n",
    "\n",
    "    Combining different methods, like keyword and embedding retrieval with reranking, ensures that the system is fast enough to meet user expectations while still providing accurate results\n",
    "-   *CPU-bases inference*: IntelÂ®'s advanced optimization technologies help with the efficient fine-tuning and inference of neural network models on CPUs. The 4th Gen IntelÂ® XeonÂ® . Scalable processors come with IntelÂ® Advanced Matrix Extensions (IntelÂ® AMX), an AI-enhanced acceleration feature. Each core of these processors includes integrated BF16 and INT8 accelerators, contributing to the acceleration of deep learning fine-tuning and inference speed. Additionally, libraries such as Intel Extension for PyTorch and IntelÂ® Extension for Transformers further optimize the performance of neural network models demanding computations on CPUs.\n",
    "-   *Retrieval performance*: We can get some failures during document retrieval, as individual segments may lack the broader context necessary to answer specific queries.  LlamaIndex offers features designed to construct a network of interlinked chunks (nodes), along with retrieval tools. These tools improve search capabilities by augmenting user queries, extracting key terms, or navigating through the connected nodes to locate the necessary information for answering queries.\n",
    "\n",
    "    The LlamaIndex framework provides a variety of retrieval methods, complete with practical examples for different use cases, including the following examples, to name a few:\n",
    "    -   Combining keyword + embedding search in a hybrid approach can enhance retrieval of specific queries. [link](https://docs.llamaindex.ai/en/stable/examples/query_engine/CustomRetrievers/)\n",
    "    -   Metadata filtering can provide additional context and improve the performance of the RAG pipeline. [link](https://docs.llamaindex.ai/en/stable/examples/vector_stores/WeaviateIndexDemo/#metadata-filtering)\n",
    "    -   Re-ranking orders the search results by considering the recency of data to the userâ€™s input query. [link](https://docs.llamaindex.ai/en/stable/examples/node_postprocessor/CohereRerank/)\n",
    "    -   Indexing documents by summaries and retrieving relevant information within the document. [link](https://docs.llamaindex.ai/en/stable/examples/index_structs/doc_summary/DocSummary/)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG best practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some of the best practices for dealing with RAG:\n",
    "\n",
    "-   *Fine-tuning the Embedding Model*: Initially, itâ€™s necessary to get the training set, which can be done by generating synthetic questions/answers from random documents. The next phase is fine-tuning the model, where adjustments are made to optimize its functioning. Following this, the model can optionally undergo an evaluation process to assess its improvements. The reported numbers from LlamaIndex show that the fine-tuning process can yield a 5-10% improvement in retrieval metrics, enabling the enhanced model to be effectively integrated into RAG applications. You can read [here](https://docs.llamaindex.ai/en/stable/optimizing/fine-tuning/fine-tuning/#finetuning-embeddings) for more information.\n",
    "-   *Evaluation*: Regularly monitoring the performance of your RAG pipeline is a recommended practice, as it allows for assessing changes and their impact on the overall results. While evaluating a model's response, which can be highly subjective, is challenging, there are several methods available to track progress effectively. LlamaIndex provides modules for assessing the quality of the generated results and the retrieval process [link](https://docs.llamaindex.ai/en/stable/optimizing/evaluation/evaluation.html). \n",
    "-   *Generative Feedback Loops*: A key aspect of generative feedback loops is injecting data into prompts. This process involves feeding specific data points into the RAG system to generate contextualized outputs. Once the RAG system generates descriptions or vector embeddings, these outputs can be stored in the database. The creation of a loop where generated data is continually used to enrich and update the database can improve the system's ability to produce better outputs.\n",
    "-   *Hybrid Search*: It is essential to keep in mind that embedding-based retrieval is not always practical for entity lookup. Implementing a hybrid search that combines the benefits of keyword lookup with additional context from embeddings can yield better results, offering a balanced approach between specificity and context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAGCourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
