{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will see how to use all the concepts learnt in the past 2 notebooks to connect with Github repositories.\n",
    "\n",
    "The following elements are going to be used : \n",
    "-   **LlamaIndex** : Data framework.\n",
    "    -   *Data Connectors* : Ingest data from various sources.\n",
    "    -   *Data Indexing* : Structure the ingested data.\n",
    "    -   *Query Engines* : Enable natural language queries to interact with the stored data.\n",
    "-   **DeepLake** : Data lake.\n",
    "    -   *Optimized Storage* : Designed for quick data retrieval.\n",
    "    -   *Data Type Support* : Handles multiple data tyoes, like images, videos and complex data structures.\n",
    "-   **Ollama** : LLM models.\n",
    "-   **python-dotenv** : Library to specify environment variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set env variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to set the values of the enviroment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set LlamaIndex settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "Settings.embed_model = OllamaEmbeddings(model=\"llama3.1:8b\") # Load it into the setting of llama index\n",
    "Settings.llm = OllamaLLM(model=\"llama3.1:8b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to change the following code to load your keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "with open('../data/keys.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "    github_token = data['GitHubToken']\n",
    "    activeloop_token = data['ActiveLoopKey']\n",
    "    github_url = data['GitHubUrl']\n",
    "    activeloop_url = data['ActiveLoopVectorStoreUrl']\n",
    "    os.environ[\"GITHUB_TOKEN\"] = github_token\n",
    "    os.environ[\"ACTIVELOOP_TOKEN\"] = activeloop_token\n",
    "    os.environ[\"GITHUB_PATH\"] = github_url\n",
    "    os.environ[\"ACTIVELOOP_PATH\"] = activeloop_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleja\\AppData\\Local\\Temp\\ipykernel_22824\\4048819749.py:30: DeprecationWarning: Call to deprecated function (or staticmethod) download_loader. (`download_loader()` is deprecated. Please install tool using pip install directly instead.)\n",
      "  download_loader(\"GithubRepositoryReader\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading RAGCourse repository by AlejandroTorresMunoz\n",
      "Documents uploaded : \n",
      "{'file_path': 'Module 1 - Basics of RAG with Langchain and LllamaIndex\\\\BasicConceptsRecap.ipynb', 'file_name': 'Module 1 - Basics of RAG with Langchain and LllamaIndex\\\\BasicConceptsRecap.ipynb', 'url': 'https://github.com/AlejandroTorresMunoz\\\\RAGCourse\\\\blob/main\\\\Module 1 - Basics of RAG with Langchain and LllamaIndex\\\\BasicConceptsRecap.ipynb'}\n",
      "{'file_path': 'Module 1 - Basics of RAG with Langchain and LllamaIndex\\\\LlamaIndexIntroduction.ipynb', 'file_name': 'Module 1 - Basics of RAG with Langchain and LllamaIndex\\\\LlamaIndexIntroduction.ipynb', 'url': 'https://github.com/AlejandroTorresMunoz\\\\RAGCourse\\\\blob/main\\\\Module 1 - Basics of RAG with Langchain and LllamaIndex\\\\LlamaIndexIntroduction.ipynb'}\n",
      "{'file_path': 'Module 1 - Basics of RAG with Langchain and LllamaIndex\\\\LlamaIndexWithGithubRepos.ipynb', 'file_name': 'Module 1 - Basics of RAG with Langchain and LllamaIndex\\\\LlamaIndexWithGithubRepos.ipynb', 'url': 'https://github.com/AlejandroTorresMunoz\\\\RAGCourse\\\\blob/main\\\\Module 1 - Basics of RAG with Langchain and LllamaIndex\\\\LlamaIndexWithGithubRepos.ipynb'}\n",
      "{'file_path': 'README.md', 'file_name': 'README.md', 'url': 'https://github.com/AlejandroTorresMunoz\\\\RAGCourse\\\\blob/main\\\\README.md'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from llama_index.readers.github import GithubRepositoryReader, GithubClient\n",
    "from llama_index.core import download_loader\n",
    "\n",
    "def parse_github_url(url):\n",
    "    # Function that takes a GitHub URL and extracts the repository owner and name using regular expressions\n",
    "    pattern = r\"https://github\\.com/([^/]+)/([^/]+)\"\n",
    "    match = re.match(pattern, url)\n",
    "    return match.groups() if match else (None, None)\n",
    "\n",
    "def validate_owner_repo(owner, repo):\n",
    "    # Function that both the repository owner and name are present\n",
    "    return bool(owner) and bool(repo)\n",
    "\n",
    "def initialize_github_client():\n",
    "    # Initializes the GitHub client using the token fetched from the environment variables\n",
    "    github_token = os.getenv(\"GITHUB_TOKEN\")\n",
    "    return GithubClient(github_token)\n",
    "\n",
    "# Check for GitHub Token\n",
    "github_token = os.getenv(\"GITHUB_TOKEN\")\n",
    "if not github_token:\n",
    "    raise EnvironmentError(\"GitHub token not found in environment variables\")\n",
    "# Check for Activeloop Token\n",
    "active_loop_token = os.getenv(\"ACTIVELOOP_TOKEN\")\n",
    "if not active_loop_token:\n",
    "    raise EnvironmentError(\"Activeloop token not found in environment variables\")\n",
    "\n",
    "github_client = initialize_github_client()\n",
    "download_loader(\"GithubRepositoryReader\")\n",
    "github_url = os.getenv(\"GITHUB_PATH\")\n",
    "owner, repo = parse_github_url(github_url) # Get the owner and repository name\n",
    "\n",
    "loader = GithubRepositoryReader(\n",
    "    github_client=github_client,\n",
    "    owner=owner,\n",
    "    repo=repo,\n",
    "    filter_file_extensions=([\".py\", \".md\"], GithubRepositoryReader.FilterType.INCLUDE),\n",
    "    verbose=False,\n",
    "    concurrent_requests=5\n",
    ")\n",
    "print(f\"Loading {repo} repository by {owner}\")\n",
    "docs = loader.load_data(branch=\"main\")\n",
    "print(\"Documents uploaded : \")\n",
    "for doc in docs:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data from GitHub has been downloaded, we create a vector store and upload the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating storage context\n",
      "Creating vector store index\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m storage_context \u001b[38;5;241m=\u001b[39m StorageContext\u001b[38;5;241m.\u001b[39mfrom_defaults(vector_store\u001b[38;5;241m=\u001b[39mvector_store) \u001b[38;5;66;03m# Storage context to store nodes, indexes, vectors...\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating vector store index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mVectorStoreIndex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_context\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Vector store index\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating query engine\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m query_engine \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39mas_query_engine() \u001b[38;5;66;03m# Query engine\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\llama_index\\core\\indices\\base.py:112\u001b[0m, in \u001b[0;36mBaseIndex.from_documents\u001b[1;34m(cls, documents, storage_context, show_progress, callback_manager, transformations, **kwargs)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents:\n\u001b[0;32m    110\u001b[0m     docstore\u001b[38;5;241m.\u001b[39mset_document_hash(doc\u001b[38;5;241m.\u001b[39mget_doc_id(), doc\u001b[38;5;241m.\u001b[39mhash)\n\u001b[1;32m--> 112\u001b[0m nodes \u001b[38;5;241m=\u001b[39m \u001b[43mrun_transformations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\n\u001b[0;32m    120\u001b[0m     nodes\u001b[38;5;241m=\u001b[39mnodes,\n\u001b[0;32m    121\u001b[0m     storage_context\u001b[38;5;241m=\u001b[39mstorage_context,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    126\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\llama_index\\core\\ingestion\\pipeline.py:100\u001b[0m, in \u001b[0;36mrun_transformations\u001b[1;34m(nodes, transformations, in_place, cache, cache_collection, **kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m             cache\u001b[38;5;241m.\u001b[39mput(\u001b[38;5;28mhash\u001b[39m, nodes, collection\u001b[38;5;241m=\u001b[39mcache_collection)\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 100\u001b[0m         nodes \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nodes\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:307\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    304\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 307\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    309\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    310\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\llama_index\\core\\node_parser\\interface.py:193\u001b[0m, in \u001b[0;36mNodeParser.__call__\u001b[1;34m(self, nodes, **kwargs)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, nodes: Sequence[BaseNode], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[BaseNode]:\n\u001b[1;32m--> 193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_nodes_from_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\llama_index\\core\\node_parser\\interface.py:165\u001b[0m, in \u001b[0;36mNodeParser.get_nodes_from_documents\u001b[1;34m(self, documents, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m doc_id_to_document \u001b[38;5;241m=\u001b[39m {doc\u001b[38;5;241m.\u001b[39mid_: doc \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents}\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m    163\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mNODE_PARSING, payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mDOCUMENTS: documents}\n\u001b[0;32m    164\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m event:\n\u001b[1;32m--> 165\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_postprocess_parsed_nodes(nodes, doc_id_to_document)\n\u001b[0;32m    168\u001b[0m     event\u001b[38;5;241m.\u001b[39mon_end({EventPayload\u001b[38;5;241m.\u001b[39mNODES: nodes})\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:307\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    304\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 307\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    309\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    310\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\llama_index\\core\\node_parser\\interface.py:260\u001b[0m, in \u001b[0;36mMetadataAwareTextSplitter._parse_nodes\u001b[1;34m(self, nodes, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes_with_progress:\n\u001b[0;32m    259\u001b[0m     metadata_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_str(node)\n\u001b[1;32m--> 260\u001b[0m     splits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_text_metadata_aware\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMetadataMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNONE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    264\u001b[0m     all_nodes\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m    265\u001b[0m         build_nodes_from_splits(splits, node, id_func\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid_func)\n\u001b[0;32m    266\u001b[0m     )\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m all_nodes\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:307\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    304\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 307\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    309\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    310\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\llama_index\\core\\node_parser\\text\\sentence.py:173\u001b[0m, in \u001b[0;36mSentenceSplitter.split_text_metadata_aware\u001b[1;34m(self, text, metadata_str)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m effective_chunk_size \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m50\u001b[39m:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    166\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetadata length (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetadata_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) is close to chunk size \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). Resulting chunks are less than 50 tokens. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m         flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    171\u001b[0m     )\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meffective_chunk_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\llama_index\\core\\node_parser\\text\\sentence.py:191\u001b[0m, in \u001b[0;36mSentenceSplitter._split_text\u001b[1;34m(self, text, chunk_size)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m    188\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mCHUNKING, payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mCHUNKS: [text]}\n\u001b[0;32m    189\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m event:\n\u001b[0;32m    190\u001b[0m     splits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split(text, chunk_size)\n\u001b[1;32m--> 191\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    193\u001b[0m     event\u001b[38;5;241m.\u001b[39mon_end(payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mCHUNKS: chunks})\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m chunks\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\llama_index\\core\\node_parser\\text\\sentence.py:265\u001b[0m, in \u001b[0;36mSentenceSplitter._merge\u001b[1;34m(self, splits, chunk_size)\u001b[0m\n\u001b[0;32m    262\u001b[0m             cur_chunk\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, (text, length))\n\u001b[0;32m    263\u001b[0m             last_index \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 265\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplits\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    266\u001b[0m     cur_split \u001b[38;5;241m=\u001b[39m splits[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cur_split\u001b[38;5;241m.\u001b[39mtoken_size \u001b[38;5;241m>\u001b[39m chunk_size:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from llama_index.vector_stores.deeplake import DeepLakeVectorStore\n",
    "from llama_index.core.storage.storage_context import StorageContext\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "# Create an object to connect with the vector store in ActiveLoop\n",
    "vector_store = DeepLakeVectorStore(\n",
    "    dataset_path=os.environ[\"ACTIVELOOP_PATH\"],\n",
    "    overwrite=True,\n",
    "    runtime={\"tensor_db\": True},\n",
    ")\n",
    "print(\"Creating storage context\")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store) # Storage context to store nodes, indexes, vectors...\n",
    "print(\"Creating vector store index\")\n",
    "index = VectorStoreIndex.from_documents(docs, storage_context=storage_context) # Vector store index\n",
    "print(\"Creating query engine\")\n",
    "query_engine = index.as_query_engine() # Query engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test the created query engine with a simple question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "intro_question = \"What is the repository about?\"\n",
    "print(f\"Test question : {intro_question}\")\n",
    "print(\"=\" * 50)\n",
    "answer = query_engine.query(intro_question)\n",
    "print(f\"Answer: {textwrap.fill(str(answer), 100)} \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAGCourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
