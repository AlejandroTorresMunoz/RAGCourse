{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will explore the concept of agents in the LlamaIndex framework. Creating an agent-based pipeline includes integrating our RAG-based application with data sources along with various tools. It is essential to remember that developing these tools for the agents requires are likely to engage with the application and predict potential usage patterns.\n",
    "\n",
    "The LlamaIndex framework offers numerous possibilites for combining agents and tools to enhance the abilities or LLM's. So, in this lesson we will demonstrate how these agents are capable of making decisions and integrating various resources to formulate a response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before start coding, we have to prepare the enviroment and settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from langchain_ollama import OllamaEmbeddings, OllamaLLM\n",
    "\n",
    "Settings.embed_model = OllamaEmbeddings(model=\"llama3.1:8b\")\n",
    "Settings.llm = OllamaLLM(model=\"llama3.1:8b\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's always interesting to tag and track data sources from the start. This mean giving a tag and it's source/origin to each document. By doing this, we will improve the chatbot's efficiency. To to this, we will introduce the `routers` to focus on the related information source to answer a question.\n",
    "\n",
    "A key step in building a data-driven application with the LlamIndex RAG system is selecting the appropiate dataset. The quality and relevance of the data are fundamental. It's a good practice to start your RAG pipeline design with a small dataset, such as web articles. This way, you can quickly test, debug and understand your RAG system.\n",
    "\n",
    "In this notebook we will use the dataset of Nikola Tesla's life, work and legacy. We employ two text documents: the first with bold future prediction that Tesla mentioned during his lifetime and the second file with biographical details about his life. We will utilize a mix of data sources from the Deep Lake vector store for the first and establish indexes from local storage for the second file. \n",
    "\n",
    "In the following code, we create a folder and we download the files to save them into the recently created folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 13902  100 13902    0     0  17794      0 --:--:-- --:--:-- --:--:-- 17845\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 23243  100 23243    0     0  43106      0 --:--:-- --:--:-- --:--:-- 43444\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\\1k\n",
    "!curl -o data\\1k\\tesla.txt https://raw.githubusercontent.com/idontcalculate/data-repo/main/machine_to_end_war.txt\n",
    "!curl -o data\\1k\\web.txt https://raw.githubusercontent.com/idontcalculate/data-repo/main/prodigal_chapter10.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAGCourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
