{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will explore the concept of agents in the LlamaIndex framework. Creating an agent-based pipeline includes integrating our RAG-based application with data sources along with various tools. It is essential to remember that developing these tools for the agents requires are likely to engage with the application and predict potential usage patterns.\n",
    "\n",
    "The LlamaIndex framework offers numerous possibilites for combining agents and tools to enhance the abilities or LLM's. So, in this lesson we will demonstrate how these agents are capable of making decisions and integrating various resources to formulate a response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before start coding, we have to prepare the enviroment and settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from langchain_ollama import OllamaEmbeddings, OllamaLLM\n",
    "\n",
    "Settings.embed_model = OllamaEmbeddings(model=\"llama3.1:8b\")\n",
    "Settings.llm = OllamaLLM(model=\"llama3.1:8b\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's always interesting to tag and track data sources from the start. This mean giving a tag and it's source/origin to each document. By doing this, we will improve the chatbot's efficiency. To to this, we will introduce the `routers` to focus on the related information source to answer a question.\n",
    "\n",
    "A key step in building a data-driven application with the LlamIndex RAG system is selecting the appropiate dataset. The quality and relevance of the data are fundamental. It's a good practice to start your RAG pipeline design with a small dataset, such as web articles. This way, you can quickly test, debug and understand your RAG system.\n",
    "\n",
    "In this notebook we will use the dataset of Nikola Tesla's life, work and legacy. We employ two text documents: the first with bold future prediction that Tesla mentioned during his lifetime and the second file with biographical details about his life. We will store both documents into local files.\n",
    "\n",
    "In the following code, we create a folder and we download the files to save them into the recently created folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 13902  100 13902    0     0  17794      0 --:--:-- --:--:-- --:--:-- 17845\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 23243  100 23243    0     0  43106      0 --:--:-- --:--:-- --:--:-- 43444\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\\1k\n",
    "!curl -o data\\1k\\tesla.txt https://raw.githubusercontent.com/idontcalculate/data-repo/main/machine_to_end_war.txt\n",
    "!curl -o data\\1k\\web.txt https://raw.githubusercontent.com/idontcalculate/data-repo/main/prodigal_chapter10.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "Settings.embed_model = OllamaEmbeddings(model=\"llama3.1:8b\") # Load it into the setting of llama index\n",
    "Settings.llm = OllamaLLM(model=\"llama3.1:8b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we read the first document and process it to store in Deep Lake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to establish a database on the Activeloop platform and upload the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Settings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Try to load the index if it is already calculated\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     storage_context \u001b[38;5;241m=\u001b[39m \u001b[43mStorageContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_defaults\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpersist_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage/tesla\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     tesla_index \u001b[38;5;241m=\u001b[39m load_index_from_storage(storage_context\u001b[38;5;241m=\u001b[39mstorage_context)\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\llama_index\\core\\storage\\storage_context.py:111\u001b[0m, in \u001b[0;36mStorageContext.from_defaults\u001b[1;34m(cls, docstore, index_store, vector_store, image_store, vector_stores, graph_store, property_graph_store, persist_dir, fs)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 111\u001b[0m     docstore \u001b[38;5;241m=\u001b[39m docstore \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mSimpleDocumentStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_persist_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpersist_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfs\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m     index_store \u001b[38;5;241m=\u001b[39m index_store \u001b[38;5;129;01mor\u001b[39;00m SimpleIndexStore\u001b[38;5;241m.\u001b[39mfrom_persist_dir(\n\u001b[0;32m    115\u001b[0m         persist_dir, fs\u001b[38;5;241m=\u001b[39mfs\n\u001b[0;32m    116\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\llama_index\\core\\storage\\docstore\\simple_docstore.py:57\u001b[0m, in \u001b[0;36mSimpleDocumentStore.from_persist_dir\u001b[1;34m(cls, persist_dir, namespace, fs)\u001b[0m\n\u001b[0;32m     56\u001b[0m     persist_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(persist_dir, DEFAULT_PERSIST_FNAME)\n\u001b[1;32m---> 57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_persist_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpersist_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\llama_index\\core\\storage\\docstore\\simple_docstore.py:74\u001b[0m, in \u001b[0;36mSimpleDocumentStore.from_persist_path\u001b[1;34m(cls, persist_path, namespace, fs)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a SimpleDocumentStore from a persist path.\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m \n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m simple_kvstore \u001b[38;5;241m=\u001b[39m \u001b[43mSimpleKVStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_persist_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpersist_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(simple_kvstore, namespace)\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\llama_index\\core\\storage\\kvstore\\simple_kvstore.py:97\u001b[0m, in \u001b[0;36mSimpleKVStore.from_persist_path\u001b[1;34m(cls, persist_path, fs)\u001b[0m\n\u001b[0;32m     96\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpersist_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpersist_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     98\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\fsspec\\spec.py:1303\u001b[0m, in \u001b[0;36mAbstractFileSystem.open\u001b[1;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[0;32m   1302\u001b[0m ac \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautocommit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_intrans)\n\u001b[1;32m-> 1303\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautocommit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\fsspec\\implementations\\local.py:195\u001b[0m, in \u001b[0;36mLocalFileSystem._open\u001b[1;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent(path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLocalFileOpener\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\fsspec\\implementations\\local.py:359\u001b[0m, in \u001b[0;36mLocalFileOpener.__init__\u001b[1;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocksize \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mDEFAULT_BUFFER_SIZE\n\u001b[1;32m--> 359\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aleja\\OneDrive\\Escritorio\\Cursos\\RAG Course ActiveLoop\\RAGCourse\\Lib\\site-packages\\fsspec\\implementations\\local.py:364\u001b[0m, in \u001b[0;36mLocalFileOpener._open\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocommit \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:/Users/aleja/OneDrive/Escritorio/Cursos/RAG Course ActiveLoop/RAGCourse/Module 3 - RAG and Agents/storage/tesla/docstore.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded the pre-computed index.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# Otherwise, generate the indexes\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     tesla_index \u001b[38;5;241m=\u001b[39m VectorStoreIndex\u001b[38;5;241m.\u001b[39mfrom_documents(tesla_docs, settings\u001b[38;5;241m=\u001b[39m\u001b[43mSettings\u001b[49m)\n\u001b[0;32m     17\u001b[0m     tesla_index\u001b[38;5;241m.\u001b[39mstorage_context\u001b[38;5;241m.\u001b[39mpersist(persist_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage/tesla\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated the index.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Settings' is not defined"
     ]
    }
   ],
   "source": [
    "from llama_index.core import load_index_from_storage\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core import StorageContext, VectorStoreIndex\n",
    "\n",
    "\n",
    "\n",
    "tesla_docs = SimpleDirectoryReader(input_files=[\"data/1k/web.txt\"]).load_data()\n",
    "\n",
    "try:\n",
    "    # Try to load the index if it is already calculated\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=\"storage/tesla\")\n",
    "    tesla_index = load_index_from_storage(storage_context=storage_context)\n",
    "    print(\"Loaded the pre-computed index.\")\n",
    "except:\n",
    "    # Otherwise, generate the indexes\n",
    "    tesla_index = VectorStoreIndex.from_documents(tesla_docs)\n",
    "    tesla_index.storage_context.persist(persist_dir=\"storage/tesla\")\n",
    "    print(\"Generated the index.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to store the embeddings of the other document locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import load_index_from_storage\n",
    "\n",
    "webtext_docs = SimpleDirectoryReader(input_files=[\"data/1k/web.txt\"]).load_data()\n",
    "\n",
    "try:\n",
    "    # Try to load the index if it is already calculated\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=\"storage/webtext\")\n",
    "    webtext_index = load_index_from_storage(storage_context=storage_context)\n",
    "    print(\"Loaded the pre-computed index.\")\n",
    "except:\n",
    "    # Otherwise, generate the indexes\n",
    "    webtext_index = VectorStoreIndex.from_documents(webtext_docs)\n",
    "    webtext_index.storage_context.persist(persist_dir=\"storage/webtext\")\n",
    "    print(\"Generated the index.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAGCourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
